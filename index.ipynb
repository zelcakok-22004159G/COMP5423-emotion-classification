{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.13.1)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (4.26.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.5.3)\n",
      "Requirement already satisfied: gensim in ./venv/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (4.3.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 1)) (56.0.0)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 1)) (0.38.4)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (1.24.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 4)) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 4)) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 4)) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./venv/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./venv/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 4)) (4.64.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./venv/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 5)) (2022.7.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in ./venv/lib/python3.8/site-packages (from gensim->-r requirements.txt (line 6)) (2.0.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in ./venv/lib/python3.8/site-packages (from gensim->-r requirements.txt (line 6)) (1.10.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./venv/lib/python3.8/site-packages (from gensim->-r requirements.txt (line 6)) (6.3.0)\n",
      "Requirement already satisfied: pyfume in ./venv/lib/python3.8/site-packages (from FuzzyTM>=0.4.0->gensim->-r requirements.txt (line 6)) (0.2.25)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: simpful in ./venv/lib/python3.8/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->-r requirements.txt (line 6)) (2.9.0)\n",
      "Requirement already satisfied: fst-pso in ./venv/lib/python3.8/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim->-r requirements.txt (line 6)) (1.8.1)\n",
      "Requirement already satisfied: miniful in ./venv/lib/python3.8/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim->-r requirements.txt (line 6)) (0.0.6)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/home/zelcakok/Desktop/Dev/COMP5423-emotion-classification/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zelcakok/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to /home/zelcakok/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/zelcakok/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m\n\u001b[1;32m     72\u001b[0m total_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader) \u001b[39m*\u001b[39m epochs\n\u001b[1;32m     73\u001b[0m scheduler \u001b[39m=\u001b[39m get_linear_schedule_with_warmup(optimizer,\n\u001b[1;32m     74\u001b[0m                                             num_warmup_steps\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,  \u001b[39m# Default value in run_glue.py\u001b[39;00m\n\u001b[1;32m     75\u001b[0m                                             num_training_steps\u001b[39m=\u001b[39mtotal_steps)\n\u001b[0;32m---> 77\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, optimizer, scheduler,\n\u001b[1;32m     78\u001b[0m                   train_dataloader, val_dataloader, epochs, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     80\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     82\u001b[0m model\u001b[39m.\u001b[39msave_pretrained(\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/trainer.py:32\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, optimzer, scheduler, train_dl, val_dl, epochs, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dl) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs\n\u001b[1;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[0;32m---> 32\u001b[0m \u001b[39mgetattr\u001b[39;49m(model, device)()\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:749\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    733\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:749\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    733\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[1;32m    735\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/Desktop/Dev/COMP5423-emotion-classification/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed(seed_val)\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, get_linear_schedule_with_warmup, BertConfig\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from utils import split_tensor_datasets, get_training_dataset_loader, get_validate_dataset_loader\n",
    "from training_kit import TrainingKit\n",
    "from trainer import Trainer\n",
    "from data_preprocessor import DataProcessor\n",
    "\n",
    "def debug_params(model):\n",
    "    params = list(model.named_parameters())\n",
    "    print('The BERT model has {:} different named parameters.\\n'.format(\n",
    "        len(params)))\n",
    "    print('==== Embedding Layer ====\\n')\n",
    "    for p in params[0:5]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    print('\\n==== First Transformer ====\\n')\n",
    "    for p in params[5:21]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    print('\\n==== Output Layer ====\\n')\n",
    "    for p in params[-4:]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "\n",
    "# Configs\n",
    "epochs = 3\n",
    "batch_size = 5\n",
    "rows_per_batch = 50\n",
    "columns = [\"Sentence\", \"Emotion\"]\n",
    "\n",
    "# Prepare the datasets\n",
    "df = pd.read_csv('data/train_data.txt', header=0, names=columns, sep=\";\")\n",
    "df = DataProcessor().process(df, columns)\n",
    "\n",
    "# Init the training kit\n",
    "training_kit = TrainingKit(\n",
    "    df, \n",
    "    feat_col_name=\"Emotion\", \n",
    "    data_col_name=\"Sentence\", \n",
    "    row_size=batch_size * rows_per_batch,\n",
    ")\n",
    "\n",
    "tensor_ds = training_kit.get_tensor_dataset()\n",
    "train_ds, val_ds = split_tensor_datasets(tensor_ds, ratio=0.7)\n",
    "\n",
    "train_dataloader = get_training_dataset_loader(train_ds, batch_size=batch_size)\n",
    "val_dataloader = get_validate_dataset_loader(val_ds, batch_size=batch_size)\n",
    "\n",
    "# Prepare the model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=len(training_kit.features),  # The number of output labels.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=5e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,  # Default value in run_glue.py\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "trainer = Trainer(model, optimizer, scheduler,\n",
    "                  train_dataloader, val_dataloader, epochs, device=\"cpu\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c00c01ab2322ad07e1de14d0ae64be8e2fa5c8e26643729024940c7ec54095b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
