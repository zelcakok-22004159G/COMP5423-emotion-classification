{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/Emotion-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.data_preprocessor import DataProcessor\n",
    "from libs.trainer import Trainer\n",
    "from libs.training_kit import TrainingKit\n",
    "from libs.utils import split_tensor_datasets, get_training_dataset_loader, get_validate_dataset_loader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertForSequenceClassification, get_linear_schedule_with_warmup, BertConfig\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed(seed_val)\n",
    "\n",
    "\n",
    "def get_class_weight(df, feat_col_name):\n",
    "    buff = {}\n",
    "    total = 0\n",
    "    features = sorted(df[feat_col_name].unique())\n",
    "    rows = df.groupby(df[feat_col_name], sort=True).size(\n",
    "    ).reset_index(feat_col_name).to_numpy().tolist()\n",
    "    for [emotion, count] in rows:\n",
    "        total += count\n",
    "    for [emotion, count] in rows:\n",
    "        buff[emotion] = 1 - (count / total)\n",
    "    weights = [buff[emotion] for emotion in features]\n",
    "    return torch.FloatTensor(weights).cpu()\n",
    "\n",
    "\n",
    "# Configs\n",
    "device = \"cuda\"\n",
    "epochs = 4\n",
    "batch_size = 50\n",
    "rows_per_batch = 320\n",
    "staging = True\n",
    "columns = [\"Sentence\", \"Emotion\"]\n",
    "\n",
    "# Prepare the datasets\n",
    "train_df = pd.read_csv('data/train_data_trimmed.txt', names=columns, sep=\";\")\n",
    "val_df = pd.read_csv('data/val_data_trimmed.txt', names=columns, sep=\";\")\n",
    "\n",
    "train_df = pd.concat([train_df, val_df])\n",
    "cls_weights = get_class_weight(train_df, columns[1])\n",
    "train_df = DataProcessor().process(train_df, columns)\n",
    "\n",
    "# Init the training kit\n",
    "training_kit = TrainingKit(\n",
    "    train_df,\n",
    "    feat_col_name=\"Emotion\",\n",
    "    data_col_name=\"Sentence\",\n",
    "    row_size=batch_size * rows_per_batch,\n",
    ")\n",
    "\n",
    "train_df = training_kit.get_tensor_dataset()\n",
    "train_ds, val_ds = split_tensor_datasets(train_df, ratio=0.9)\n",
    "\n",
    "train_dataloader = get_training_dataset_loader(train_ds, batch_size=batch_size)\n",
    "val_dataloader = get_validate_dataset_loader(val_ds, batch_size=batch_size)\n",
    "\n",
    "# Prepare the model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels=len(training_kit.features),  # The number of output labels.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=5e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,  # Default value in run_glue.py\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "trainer = Trainer(model, optimizer, scheduler, train_dataloader,\n",
    "                  val_dataloader, cls_weights, epochs, device=device, staging=staging)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"model\")\n",
    "training_kit.save(\"model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c00c01ab2322ad07e1de14d0ae64be8e2fa5c8e26643729024940c7ec54095b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
